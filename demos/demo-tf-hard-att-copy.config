#!crnn/rnn.py
# kate: syntax python;
# -*- mode: python -*-
# sublime: syntax 'Packages/Python Improved/PythonImproved.tmLanguage'
# vim:set expandtab tabstop=4 fenc=utf-8 ff=unix ft=python:

# Also see demo-tf-att-copy.config for a soft attention variant of the same task.

# network topology based on:
# https://github.com/rwth-i6/returnn-experiments/blob/master/2019-librispeech-system/attention/base2.bs18k.curric3.config
# adapted/simplified/extended for hard attention

# This is still work-in-progress. It does not quite work yet... Also has some cheating in it...

import os, sys
from Util import get_login_username
demo_name, _ = os.path.splitext(__file__)
print("Hello, experiment: %s" % demo_name)

# task
use_tensorflow = True
task = config.value("task", "train")

debug_mode = 'pydevd' in sys.modules or bool(int(os.environ.get('DEBUG', False)))

if task == "train":
  # TODO: we should be able to set this higher than 5==T (at most to classes)
  # but this currently does not work, investigate.
  beam_size = 5
else:
  beam_size = 12

# data
num_inputs = 10
num_outputs = {"data": [num_inputs,1], "classes": [num_inputs,1], "position": [20, 1]}
train = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 1000, "minlen": 5, "maxlen": 5}
# dev = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 50, "minlen": 1, "maxlen": 20, "fixed_random_seed": 42}
dev = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 50, "minlen": 20, "maxlen": 20, "fixed_random_seed": 42}

batch_size = 5000
log_batch_size = True
#max_seqs = 10


EncKeyTotalDim = 20
EncValueTotalDim = 20
target = "classes"


def rel_embed(source, network):
  import tensorflow as tf
  from TFUtil import nd_indices, expand_dims_unbroadcast, where_bc
  x = source(0, as_data=True, auto_convert=False)  # (B, T, K)
  v = source(1, as_data=True, auto_convert=False)  # (B, Ts, K)
  assert v.dim == x.dim
  t = source(2, auto_convert=False)  # (B,)
  vi = source(3, as_data=True, auto_convert=False)  # (K,)
  assert vi.batch_shape == (x.dim,)
  t = tf.Print(t, ["t:", t])
  time_dim = tf.shape(x.placeholder)[x.time_dim_axis]
  batch_dim = tf.shape(x.placeholder)[x.batch_dim_axis]
  assert len(v.shape) == 2 and all([isinstance(d, int) for d in v.shape])
  ts_dim = v.shape[0]
  indices = tf.expand_dims(tf.range(ts_dim), axis=0)  # (1,Ts)
  indices = indices + tf.expand_dims(t, axis=1)  # (B,Ts)
  indices = tf.minimum(indices, time_dim - 1)
  indices = nd_indices(indices)  # (B,Ts,2)
  # x0 = tf.scatter_nd(indices=indices, updates=v.placeholder, shape=[batch_dim, time_dim, x.dim])  # (B,T,K)
  # return x.placeholder + x0
  # if x.time_dim_axis == 1:
  #    x0 = tf.transpose(x0, [1, 0, 2])
  # i = network.get_rec_step_index()
  # x1 = tf.scatter_nd([[i]], [vi.placeholder], [time_dim, x.dim])  # (T,K). cheating
  # x1 = expand_dims_unbroadcast(x1, axis=0, dim=batch_dim)  # (B,T,K)
  # x1 = tf.Print(x1, ["i:", i, "t:", t], summarize=5)
  # return x.placeholder + x0 + x1
  return x.placeholder
  # return x0


def energy_pp(source, network):
  import tensorflow as tf
  from TFUtil import nd_indices, expand_dims_unbroadcast, where_bc
  x = source(0, as_data=True)
  batch_dim = tf.shape(x.placeholder)[x.batch_dim_axis]
  time_dim = tf.shape(x.placeholder)[x.time_dim_axis]
  i = network.get_rec_step_index()
  #     #x1 = tf.scatter_nd([[i]], [1.0], [time_dim])  # (T)
  #
  #     # cheating: set for t=i 0, otherwise -inf
  #     # x1 = where_bc(tf.equal(tf.range(time_dim), i), 0.0, float("-inf"))
  #
  #     # cheating set for for t>=i energy=0, otherwise (left of dec-pos) -inf
  #     # x1 = where_bc(tf.greater_equal(tf.range(time_dim), i), 0.0, float("-inf"))
  #     # x1 = expand_dims_unbroadcast(x1, axis=0, dim=batch_dim)  # (B,T)
  #     x1 = x.placeholder
  #     assert x.batch_dim_axis == 0 and x.time_dim_axis == 1
  #     if debug_mode:
  #       x1 = tf.Print(x1, ["i:", i, "energy:", x1[0]], summarize=10)
  #     return x1
  x2 = where_bc(tf.greater_equal(tf.range(time_dim), i), 0.0, float("-inf"))
  res = x.placeholder + x2
  # res = tf.Print(res, ["i:", i, "energy:", res], summarize=10)
  return res



def loss_ce(source):
    import tensorflow as tf
    from TFUtil import nd_indices, safe_log
    x = source(0, auto_convert=False, as_data=True).copy_as_batch_major()
    y = source(1, auto_convert=False, as_data=True).copy_as_batch_major()

    assert y.batch_ndim == 1 and x.batch_ndim == y.batch_ndim + 1 and x.dim == y.dim
    x_ = safe_log(x.placeholder)
    assert x_.op.type != "Log"  # it means we used LogSoftmax or so
    out = -tf.gather_nd(x_, nd_indices(y.placeholder))
    # out = tf.Print(out, [x.name, "loss", out, "y", y.placeholder])
    return out


def cheating_score_combine(layer, scores_in, scores_base, t, end_flags, batch_dim, scores_beam_in,
                                     base_beam_in):
  """ This function cheats the beam-scores by simply setting score_in[t]
  to a very high value.
  :param layer:
  :param scores_in:
  :param scores_base:
  :param t:
  :param end_flags:
  :param batch_dim:
  :param scores_beam_in:
  :param base_beam_in:
  :return:
  """
  from TFUtil import optional_add, optional_mul, where_bc
  import tensorflow as tf
 # we cheat by setting the score for the current timestep to a high value
  max_len = tf.shape(scores_in)[-1]
  one_hot_score = where_bc(tf.equal(tf.range(max_len), t), -0.5, -2.3)
  # one_hot_score = tf.Print(one_hot_score, ["range", t, tf.range(scores_beam_in), "one_hot", one_hot_score], summarize=999)
  # common_shape = get_common_shape([scores_in, one_hot_score])

  one_hot_scale = 0.5
  prob_scale = 1.0
  base_beam_score_scale = 1.

  scores = optional_add(
    optional_mul(one_hot_score, one_hot_scale),
    optional_mul(scores_in, prob_scale),
    optional_mul(scores_base, base_beam_score_scale))  # (batch, beam_in, dim)

  # scores = tf.Print(scores, ["i:", t, "scores_beam_in:", scores_beam_in, "base_beam_in:", base_beam_in], summarize=9999)
  # scores = tf.Print(scores, ["i:", t, "scores_in:", scores_in, "scores_base:", scores_base], summarize=9999)
  return scores


network = {
  "input": {"class": "linear", "activation": "tanh", "n_out": 20},
  "encoder": {"class": "copy", "from": "input"},  # dim: EncValueTotalDim
  "enc_ctx": {"class": "linear", "activation": None, "with_bias": True,
              "from": "encoder", "n_out": EncKeyTotalDim, "dropout": 0.2},
  "enc_value": {"class": "copy", "from": "encoder"},  # (B, enc-T, D)
  "inv_fertility": {"class": "linear", "activation": "sigmoid", "with_bias": False, "from": "encoder", "n_out": 1},
  # "linear_alignment_mask": {"class": "monotonic_mask", "from": "input"},  # (B, T, T)

  # "soft_baseline": {"class": "rec", "from": [], "unit": {
  #   "s_transformed": {"class": "linear", "activation": None, "with_bias": False,
  #                     "from": "s", "n_out": EncKeyTotalDim, "is_output_layer": True},
  #   "weight_feedback": {"class": "linear", "activation": None, "with_bias": False, "from": ["prev:accum_att_weights"],
  #                       "n_out": EncKeyTotalDim},
  #   "att_weights_with_fertility": {"class": "eval", "from": ["att_weights", "base:inv_fertility"],
  #                                  "eval": "source(0) * source(1) * 0.5"},
  #   "accum_att_weights": {"class": "cumsum", "from": "att_weights_with_fertility"},
  #   "energy_in": {"class": "combine", "kind": "add", "from": ["base:enc_ctx", "s_transformed", "weight_feedback"],
  #                 "n_out": EncKeyTotalDim},
  #   # "energy_in1": {"class": "eval", "from": ["energy_in", "t_rel_var", "prev:t", "i_var"],
  #   #    "eval": "self.network.get_config().typed_value('rel_embed')(source, network=self.network)"},
  #   "energy_tanh": {"class": "activation", "activation": "tanh", "from": "energy_in"},
  #   "energy": {"class": "linear", "activation": None, "with_bias": False, "from": "energy_tanh", "n_out": 1},
  #   # (B, enc-T, 1)
  #   "energy0": {"class": "squeeze", "axis": "f", "from": "energy"},  # (B, enc-T)
  #   "one": {"class": "constant", "from": [], "value": 1, "dtype": "int32"},
  #   "i": {"class": "eval", "from": ["one", "prev:i"], "eval": "tf.to_int32(source(0) + source(1))",
  #         "initial_output": -1},  # (B,)
  #   "att_weights": {"class": "softmax_over_spatial", "from": "energy0", "start": "i"},  # (B, enc-T)
  #
  #   "att": {"class": "generic_attention", "weights": "att_weights", "base": "base:enc_value"},  # (B, V)
  #
  #   "s": {"class": "rnn_cell", "unit": "LSTMBlock", "from": ["prev:target_embed", "prev:att"], "n_out": 20},
  #   "readout_in": {"class": "linear", "from": ["s", "prev:target_embed", "att"], "activation": None, "n_out": 50},
  #   "readout": {"class": "reduce_out", "mode": "max", "num_pieces": 2, "from": "readout_in"},
  #   "output_prob": {"class": "softmax", "from": "readout", "target": target, "loss": "ce"},
  #   "output": {"class": "choice", "from": "output_prob", "target": target, "beam_size": beam_size},
  #   #"end": {"class": "compare", "from": "output", "value": 0},
  #   'target_embed': {'class': 'linear', 'activation': None, "with_bias": False, 'from': 'output', "n_out": 20},
  # }, "target": target, "max_seq_len": "max_len_from('base:encoder')", "is_output_layer": False},

  "output": {"class": "rec", "from": [], 'only_on_search': True, "cheating": True, "unit": {
    "s_transformed": {"class": "linear", "activation": None, "with_bias": False,
                      "from": "s", "n_out": EncKeyTotalDim,},
    # "t_rel_var": {"class": "variable", "shape": (5, EncKeyTotalDim)},
    # "i_var": {"class": "variable", "shape": (EncKeyTotalDim,), "add_batch_axis": False},
    # we limit the dt to 5, so we can have a fixed-size embedding
    # "rel_t_embed": {"class": "linear", "activation": "None", "with_bias": False, "from": "prev:t", "n_out": 5},
    "weight_feedback": {"class": "linear", "activation": None, "with_bias": False, "from": ["prev:accum_att_weights"],
                        "n_out": EncKeyTotalDim},
    "att_weights_with_fertility": {"class": "eval", "from": ["att_weights", "base:inv_fertility"],
                                   "eval": "source(0) * source(1) * 0.5"},
    "accum_att_weights": {"class": "cumsum", "from": "att_weights_with_fertility"},

    "energy_in": {"class": "combine", "kind": "add", "from": ["base:enc_ctx", "s_transformed", "weight_feedback"],
                  "n_out": EncKeyTotalDim},
    # "energy_in1": {"class": "eval", "from": ["energy_in", "t_rel_var", "prev:t", "i_var"],
    #    "eval": "self.network.get_config().typed_value('rel_embed')(source, network=self.network)"},
    "energy_tanh": {"class": "activation", "activation": "tanh", "from": ["energy_in"]},
    "energy": {"class": "linear", "activation": None, "with_bias": False, "from": "energy_tanh", "n_out": 1},
    # (B, enc-T, 1)
    "energy0": {"class": "squeeze", "axis": "f", "from": "energy"},  # (B, enc-T)
    # "energy1": {"class": "eval", "from": "energy0",
    #   "eval": "self.network.get_config().typed_value('energy_pp')(source, network=self.network)"},
    # "att_weights": {"class": "softmax_over_spatial", "from": "energy0", "use_time_mask": False},  # (B, enc-T)

    # "prev_t_advance": {"class": "combine", "from": ["one", "prev:t"], "kind": "eval": "source(0) + 1"},  # (B,)
    #"pos": {"class": "source", "data_key": "position", "from": []},
    "att_weights_in": {"class": "softmax_over_spatial", "from": "energy0"}, # "start": "prev:t"},  # (B, enc-T)
    #"att_weights": {"class": "print", "from": "att_weights_in"},
     "att_weights": {"class": "copy", "from": "att_weights_in"},
    # ChoiceLayer works on the feature axis.
    "att_weights0": {"class": "reinterpret_data", "from": "att_weights", "set_axes": {"f": "t"}},

    "one": {"class": "constant", "from": [], "value": 1,
            "dtype": "int32", "collocate_with": "output"},
    "i": {"class": "combine", "kind": "add", "from": ["one", "prev:i"],
        "initial_output": 0, "collocate_with": "output"},  # (B,)

    "t": {
      "class": "choice", "from": ["att_weights0"], "target": None,
      "beam_size": beam_size, "search": True,
      # "random_sample_scale": 0.1,  # Gumbel-trick
      "base_beam_score_scale": 0.0 if task == "train" else 1.0,  # later remove...
      "prob_scale": 1.,
      "length_normalization": False, "initial_output": 0,
      #"custom_score_combine": cheating_score_combine,
    },  # (B,)
    # "t": {"class": "print", "from": "t_in", "initial_output": 0},
    # "t": {"class": "copy", "from": "t_in", "initial_output": 0},

    # "t_ce": {"class": "copy", "from": "t", "target": "layer:i",
    #          "collocate_with": "t", "loss": "ce"},
    # "rel_t": {"class": "eval", "from": ["t", "prev:t"],
    #          "eval": "tf.clip_by_value(source(0) - source(1), 0, 4)",
    #          "out_type": {"sparse": True, "dtype": "int8", "dim": 5, "shape": ()}}, # 0-4, sparse
    # "rel_t_embed": {"class": "linear", "activation": None, "with_bias": False,
    #                "from": "rel_t", "n_out": EncKeyTotalDim},

    # collocate_with to have it with the current beam
    #"t_ce": {
    #  "class": "eval", "from": ["att_weights0", "t"], "eval": "self.network.get_config().typed_value('loss_ce')(source)",
    #  "loss": "as_is", "collocate_with": "t",
    #  "out_type": {"shape": (), "feature_dim_axis": None, "time_dim_axis": None, "dtype": "float32"}},
    # "linear_alignment": {"class": "copy", "from": "base:linear_alignment"},
    # output: t, target: linear_alignment
    # "t_ce": {
    #  "class": "eval", "from": ["att_weights0", "t"], "eval": "self.network.get_config().typed_value('loss_ce')(source)",
    #  "loss": "as_is", "collocate_with": "t",
    #  "out_type": {"shape": (), "feature_dim_axis": None, "time_dim_axis": None, "dtype": "float32"}},

    "att_hard": {"class": "gather_nd", "position": "t", "from": "base:enc_value"},  # (B, V)
    # "att_soft": {"class": "generic_attention", "weights": "att_weights", "base": "base:enc_value"},  # (B, V)
    # "att": {"class": "eval", "from": ["att_hard", "att_soft"], "eval": "source(0) * 0.5 + source(1) * 0.5"},
    "att": {"class": "copy", "from": "att_hard"},
    "s": {"class": "rnn_cell", "unit": "LSTMBlock", "from": ["prev:target_embed", "prev:att"], "n_out": 20},
    #"readout_in": {"class": "linear", "from": ["s", "prev:target_embed", "att"], "activation": None, "n_out": 50},
    #"readout": {"class": "reduce_out", "mode": "max", "num_pieces": 2, "from": "readout_in"},
    "output_prob": {"class": "softmax", "from": ["s", "prev:target_embed", "att"], "n_out": num_inputs}, #, "target": target,
                    # "loss": "ce", "loss_opts": {"scale": 0},},

    # We do search here, because we want the rec-layer to output the beams
    # on which we can compute the loss (e.g. policy gradient) and not on the true label.
    'output': {
      'class': 'choice', 'target': target, 'search': True,
      'prob_scale': 0.1,  # lower is better for convergence, 11 epochs to 8% FER
      # does not converge with low values, slow convergence with 1.0:
      'base_beam_score_scale': 0.75,
      'beam_size': beam_size, 'from': "output_prob"},
    #"output_ce": {
    #    "class": "eval", "from": ["output_prob", "output"], "eval": "self.network.get_config().typed_value('loss_ce')(source)",
    #     "loss": "as_is", "collocate_with": "output",
    #     "out_type": {"shape": (), "feature_dim_axis": None, "time_dim_axis": None, "dtype": "float32"}},


    # "end": {"class": "compare", "from": "i", "value": 5, "only_on_eval": False},
    #"end": {"class": "eval", "from": ["end_eval"]}
    'target_embed': {'class': 'linear', 'activation': None, "with_bias": False, 'from': 'output', "n_out": 20},

  }, "target": target, "max_seq_len": "max_len_from('base:encoder')"},

  # extra layer, so we can delete it using pretrain config
  "decide": {"class": "decide", "from": "output", "only_on_search": True,
             "is_output_layer": True},
  # we don't want to decide yet, compute loss on beam.
  "policy_gradient": {"class": "copy", "from": "output",
                      "loss": "expected_loss",
                      "only_on_search": True,
                      "loss_opts": {
                        "loss": {
                          "class": "ce",
                        },
                        "loss_kind": "error",  # FER
                        # "loss_kind": "value",  # CE score
                      }},

}

if debug_mode:
  # add debug-print layers
  decoder_layers = ["att_weights", "t"]  #"energy_in1", "energy0", "output"]
  # decoder_layers = []
  d = network['output']['unit']
  for layer in decoder_layers:
    if layer not in d:
      continue
    debug_layer = layer + "_debug"
    assert debug_layer not in d
    d[debug_layer] = {"class": "eval", "from": layer,
                "eval": "tf.Print(source(0), [\"i:\", self.network.get_rec_step_index(),"
                        "\"%s:\", source(0)[0]], summarize=10)" % layer}
    if "initial_output" in d[layer]:
      d[debug_layer]["initial_output"] = d[layer]["initial_output"]

    # change all links to the debug-layers
    for l, desc in d.items():
      if l.endswith("_debug"):
        continue
      sources = desc.get("from", [])
      if isinstance(sources, str):
        sources = [sources]
        desc["from"] = sources
      assert isinstance(sources, (list, tuple))
      for key, value in desc.items():
        if isinstance(value, (tuple, list)):
          if layer in value:
            idx = desc["from"].index(layer)
            desc["from"].pop(idx)
            desc["from"].insert(idx, debug_layer)
        elif isinstance(value, str):
          if layer == value:
            desc[key] = debug_layer  # replace with debug_layer
          elif "prev:"+layer == value:
            desc[key] = "prev:"+debug_layer

search_train_network_layers = []  # maybe add later
maybe_search_layers = ["decide", "policy_gradient"]  #, "edit_distance", "policy_gradient"]
for layer in maybe_search_layers:
  if layer in network:
    search_train_network_layers.append(layer)


def custom_construction_algo(idx, net_dict):
  # For debugging, use: python3 ./crnn/Pretrain.py config... Maybe set repetitions=1 below.
  num_epochs_ce = 10  # (pretrain reps * num) of only CE training
  num_epochs_weighted = 0
  unit = net_dict["output"]["unit"]
  if idx == num_epochs_ce + num_epochs_weighted:
    return None  # stop pretraining, use hard-attention only

  # CHEATING!
  unit["t"]["custom_score_combine"] = cheating_score_combine
  # unit["att_hard"]["position"] = "prev:i"
  return net_dict

  # During pretraining we use linear alignment for t
  # unit["t"]["target"] = "linear_alignment"

  # weighted epochs means we still use CE loss, but gradually decrease it.
  if idx+1 > num_epochs_ce and idx-num_epochs_ce<num_epochs_weighted:
    progress = (idx-num_epochs_ce) / (num_epochs_weighted)  # in [0, 1]
    #unit["output_prob"]["loss_opts"]["scale"] = 1. - progress
    return net_dict

  # prepare network for CE training
  # we had CE loss disabled by setting the scale to 0 (so we can still see the FER),
  # now we enable it.

  unit["output_prob"]["loss_opts"]["scale"] = 1
  net_dict["output"]["only_on_search"] = False

  # enforce monotonicity during CE training
  # without this constraint it doesn't work!
  unit["att_weights_in"]["start"] = "i"

  #del unit["t"]  # remove choice layer
  unit.pop("t_ce", None)
  del unit["att"]
  unit["att"] = {"class": "copy", "from": "att_soft"}  # use ONLY soft attention
  del unit["att_hard"]
  del unit["t"]
  unit.pop("output_ce", None)

  del net_dict["decide"]
  del net_dict["search_output"]

  from pprint import pprint
  pprint(net_dict)
  return net_dict



pretrain = {"repetitions": config.int("pretrain_reps", 5), "construction_algo": custom_construction_algo}
debug_print_layer_output_template = True
debug_print_layer_output_shape = False

stop_on_nonfinite_train_score = False

adam = True
learning_rate = 0.1
gradient_noise = 0.3
model = "/tmp/%s/crnn/%s/model" % (get_login_username(), demo_name)
num_epochs = 100
log_verbosity = 5
